{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"A9fFyXDs0lGS","outputId":"cf313aab-059c-47b4-9ed9-92354a0b03a5"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\LegendKi\\anaconda3\\envs\\sttt_whisper\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["Running on local URL:  http://127.0.0.1:7860\n","Running on public URL: https://7c5b9839ed7fa57b09.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["<div><iframe src=\"https://7c5b9839ed7fa57b09.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":1,"metadata":{},"output_type":"execute_result"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\LegendKi\\anaconda3\\envs\\sttt_whisper\\lib\\site-packages\\gradio\\processing_utils.py:188: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n","  warnings.warn(warning.format(data.dtype))\n","c:\\Users\\LegendKi\\anaconda3\\envs\\sttt_whisper\\lib\\site-packages\\gradio\\processing_utils.py:188: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n","  warnings.warn(warning.format(data.dtype))\n","C:\\Users\\LegendKi\\AppData\\Local\\Temp\\ipykernel_21388\\2052110243.py:19: UserWarning: PySoundFile failed. Trying audioread instead.\n","  audio_input, sampling_rate = librosa.load(audio_file, sr=16000, mono=True)\n","c:\\Users\\LegendKi\\anaconda3\\envs\\sttt_whisper\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n","\tDeprecated as of librosa version 0.10.0.\n","\tIt will be removed in librosa version 1.0.\n","  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"]}],"source":["import os\n","import subprocess\n","from pytube import YouTube\n","from transformers import WhisperProcessor, WhisperForConditionalGeneration, pipeline\n","import whisper\n","import librosa\n","import numpy as np\n","import torch\n","import gradio as gr\n","import sys\n","\n","sys.setrecursionlimit(10**8)\n","\n","processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n","model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n","whisper_model = whisper.load_model(\"small\", device=\"cuda\")\n","\n","def translate_speech(audio_file, target_language):\n","    audio_input, sampling_rate = librosa.load(audio_file, sr=16000, mono=True)\n","    audio_input = np.expand_dims(audio_input, axis=0)\n","    input_features = processor(audio_input, sampling_rate=sampling_rate, return_tensors=\"pt\").input_features\n","    model.to(\"cuda\")\n","    input_features = input_features.to(\"cuda\")\n","    og_audio = whisper.load_audio(audio_file)\n","    og_audio = whisper.pad_or_trim(og_audio)\n","    mel = whisper.log_mel_spectrogram(og_audio).to(model.device)\n","    _, probs = whisper_model.detect_language(mel)\n","    detected_lng = max(probs, key=probs.get)\n","    predicted_ids = model.generate(input_features, language=str(target_language), task=\"transcribe\")\n","    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n","    return detected_lng, transcription\n","\n","def get_audio_from_youtube(url):\n","    yt = YouTube(url)\n","    video = yt.streams.filter(only_audio=True).first()\n","    out_file = video.download(output_path=\".\")\n","    base, ext = os.path.splitext(out_file)\n","    new_file = base + '.mp3'\n","    os.rename(out_file, new_file)\n","    return new_file\n","\n","def translate_mic(micorphone_input, target_language):\n","    return translate_speech(micorphone_input, target_language)\n","\n","def translate_audio_file(audio_file, target_language):\n","    return translate_speech(audio_file, target_language)\n","\n","def translate_youtube_video(url, target_language):\n","    audio_file = get_audio_from_youtube(url)\n","    return translate_speech(audio_file, target_language)\n","\n","gr.close_all()\n","\n","with gr.Blocks() as demo:\n","    gr.Markdown(\"## Whisper Translation System\")\n","\n","    with gr.Tab(\"Translate Speech\"):\n","        with gr.Row():\n","            microphone_input = gr.Audio(source=\"microphone\", type=\"filepath\", label=\"Record your speech\")\n","            language_dropdown = gr.Dropdown([\"english\", \"japanese\", \"korean\", \"chinese\", 'german', 'spanish', 'russian'], label=\"Select Target Language\")\n","            translate_button = gr.Button(\"Translate Speech\")\n","            translate_button.click(translate_mic, inputs=[microphone_input, language_dropdown])\n","        with gr.Row():\n","            detected_language = gr.Textbox(label=\"Detected Language\")\n","            translated_text_mic = gr.Textbox(label=\"Translated Text\")\n","            translate_button.click(translate_mic, inputs=[microphone_input, language_dropdown], outputs=[detected_language, translated_text_mic])\n","\n","    with gr.Tab(\"Translate Audio File\"):\n","        with gr.Row():\n","            audio_input = gr.Audio(source=\"upload\", type=\"filepath\", label=\"Upload Audio File\")\n","            language_dropdown = gr.Dropdown([\"english\", \"japanese\", \"korean\", \"chinese\", 'german', 'spanish', 'russian'], label=\"Select Target Language\")\n","            translate_button = gr.Button(\"Translate Audio\")\n","        with gr.Row():\n","            detected_language = gr.Textbox(label=\"Detected Language\")\n","            translated_text = gr.Textbox(label=\"Translated Text\")\n","            translate_button.click(translate_audio_file, inputs=[audio_input, language_dropdown], outputs=[detected_language, translated_text])\n","\n","    with gr.Tab(\"Translate YouTube Video\"):\n","        with gr.Row():\n","            youtube_input = gr.Textbox(label=\"Enter YouTube URL\")\n","            language_dropdown_youtube = gr.Dropdown([\"english\", \"japanese\", \"korean\", \"chinese\", 'german', 'spanish', 'russian'], label=\"Select Target Language\")\n","            translate_youtube_button = gr.Button(\"Translate Video\")\n","        with gr.Row():\n","            detected_language_youtube = gr.Textbox(label=\"Detected Language\")\n","            translated_text_youtube = gr.Textbox(label=\"Translated Text\")\n","            translate_youtube_button.click(translate_youtube_video, inputs=[youtube_input, language_dropdown_youtube], outputs=[detected_language_youtube, translated_text_youtube])\n","\n","demo.queue().launch(share=True)\n"]}],"metadata":{"kernelspec":{"display_name":"sttt_whisper","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}